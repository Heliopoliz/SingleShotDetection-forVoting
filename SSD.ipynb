{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet import gluon, image, init, nd, contrib, autograd\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_predict(numAnchor, numClass):\n",
    "    return nn.Conv2D(numAnchor * (numClass + 1), kernel_size = 3, padding = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_predict(numAnchor):\n",
    "    return nn.Conv2D(numAnchor * 4, kernel_size = 3, padding = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(vec, level):\n",
    "    level.initialize()\n",
    "    return level(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat(prediction):\n",
    "    return prediction.transpose((0, 2, 3, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(predictions):\n",
    "    return nd.concat(*[flat(p) for p in predictions], dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_size_level(numChannels):\n",
    "    lev = nn.Sequential()\n",
    "    for _ in range(2):\n",
    "       lev.add(nn.Conv2D(numChannels, kernel_size = 3, padding = 1),\n",
    "              nn.BatchNorm(in_channels = numChannels),\n",
    "              nn.Activation('relu'))\n",
    "    lev.add(nn.MaxPool2D(2))\n",
    "    return lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_net():\n",
    "    lev = nn.Sequential()\n",
    "    for i in [16, 32, 64]:\n",
    "        lev.add(half_size_level(i))\n",
    "    return lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_level(i):\n",
    "    if i == 0:\n",
    "        lev = base_net()\n",
    "    elif i == 4:\n",
    "        lev = nn.GlobalMaxPool2D()\n",
    "    else:\n",
    "        lev = half_size_level(128)\n",
    "    return lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_forward(X, lev, size, ratio, cls_predictor, bbox_predictor):\n",
    "    Y = lev(X)\n",
    "    anchors = contrib.ndarray.MultiBoxPrior(Y, sizes=size, ratios=ratio)\n",
    "    cls_predictions = cls_predictor(Y)\n",
    "    bbox_predictions = bbox_predictor(Y)\n",
    "    return (Y, anchors, cls_predictions, bbox_predictons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],\n",
    "         [0.88, 0.961]]\n",
    "ratios = [[1, 2, 0.5]] * 5\n",
    "numAnchors = len(sizes[0]) + len(ratios[0]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD(nn.Block):\n",
    "    def __init__(self, numClasses, **kwargs):\n",
    "        super(SSD, self).__init__(**kwargs)\n",
    "        self.numClasses = numClasses\n",
    "        for i in range(5):\n",
    "            setattr(self, 'lev_%d' % i, create_level(i))\n",
    "            setattr(self, 'cls_%d' % i, cls_predict(numAnchors, numClasses))\n",
    "            setattr(self, 'bbox_%d' % i, bbox_predict(numAnchors))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        anchors, cls_predictions, bbox_predictions = [None] * 5, [None] * 5, [None] * 5\n",
    "        for i in range(5):\n",
    "            X, anchors[i], cls_predictions[i], bbox_predictions[i] = level_forward(\n",
    "            X, getattr(self, 'lev_%d' % i), sizes[i], ratios[i],\n",
    "            getattr(self, 'cls_%d' % i), getattr(self, 'bbox_%d' % i))\n",
    "        \n",
    "        return (nd.concat(*anchors, dim = 1), concat(cls_predctions).reshape((0, -1, self.numClasses + 1)), concat(bbox_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'half_size_level' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4764b0150fd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSSD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumClasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtry_gpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-878f3d06cfc2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, numClasses, **kwargs)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumClasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumClasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lev_%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cls_%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumAnchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumClasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bbox_%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumAnchors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-7d48ebd87127>\u001b[0m in \u001b[0;36mcreate_level\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mlev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGlobalMaxPool2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mlev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhalf_size_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'half_size_level' is not defined"
     ]
    }
   ],
   "source": [
    "net = SSD(numClasses = 1)\n",
    "net.initialize()\n",
    "batch_size = 32\n",
    "\n",
    "ctx = d2l.try_gpu()\n",
    "net = SSD(numClasses = 1)\n",
    "\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate' : 0.2, 'wd' : 5e-4})\n",
    "\n",
    "cls_loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "bbox_loss = gloss.L1Loss()\n",
    "\n",
    "def compute_loss(cls_predictions, cls_labels, bbox_predictions, bbox_labels, bbox_masks):\n",
    "    cls_l = cls_loss(cls_predictions, cls_labels)\n",
    "    bbox_l = bbox_loss(bbox_predictions * bbox_masks, bbox_labels * bbox_masks)\n",
    "    return cls_l + bbox_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_eval(cls_predictions, cls_labels):\n",
    "    # 由于类别预测结果放在最后一维，argmax需要指定最后一维\n",
    "    return (cls_predictions.argmax(axis=-1) == cls_labels).sum().asscalar()\n",
    "\n",
    "def bbox_eval(bbox_predictions, bbox_labels, bbox_masks):\n",
    "    return ((bbox_labels - bbox_predictions) * bbox_masks).abs().sum().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    acc_sum, mae_sum, n, m = 0.0, 0.0, 0, 0\n",
    "    train_iter.reset()  # 从头读取数据\n",
    "    start = time.time()\n",
    "    for batch in train_iter:\n",
    "        X = batch.data[0].as_in_context(ctx)\n",
    "        Y = batch.label[0].as_in_context(ctx)\n",
    "        with autograd.record():\n",
    "            # 生成多尺度的锚框，为每个锚框预测类别和偏移量\n",
    "            anchors, cls_preds, bbox_preds = net(X)\n",
    "            # 为每个锚框标注类别和偏移量\n",
    "            bbox_labels, bbox_masks, cls_labels = contrib.nd.MultiBoxTarget(\n",
    "                anchors, Y, cls_preds.transpose((0, 2, 1)))\n",
    "            # 根据类别和偏移量的预测和标注值计算损失函数\n",
    "            l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels,\n",
    "                          bbox_masks)\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "        acc_sum += cls_eval(cls_preds, cls_labels)\n",
    "        n += cls_labels.size\n",
    "        mae_sum += bbox_eval(bbox_preds, bbox_labels, bbox_masks)\n",
    "        m += bbox_labels.size\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('epoch %2d, class err %.2e, bbox mae %.2e, time %.1f sec' % (\n",
    "            epoch + 1, 1 - acc_sum / n, mae_sum / m, time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
